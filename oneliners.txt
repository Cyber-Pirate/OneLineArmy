
#get js files with the output of gau or waybackurls or something else

getjs(){
        cat $1 | grep '\.js$' | httpx -status-code -mc 200 -content-type -no-color -silent | grep 'application/javascript' | sed -e 's/\[application\/javascript]//g' | sed 's/\[200]//g' | tee -a js.txt
}

#Grab all the subdoamins with this

subsof(){
        echo $1 | assetfinder -subs-only | sort -u >> asub.txt;
        echo $1 | subfinder -silent | sort -u >> subf.txt;
        cat asub.txt subf.txt | sort -u >> sub.txt ;
        rm -rf asub.txt subf.txt;
        amass enum -nf sub.txt -d $1 -noalts -passive >> amass.txt;
        cat subs.txt amass.txt | sort -u >> subs.txt;
        rm -rf amass.txt sub.txt;
        cat subs.txt | httpx -silent | sed 's/https\?:\/\///' >> alive-subs.txt
}

#Grab all urls and get those unique and valid

grab_url(){
          echo $1 | gau -subs >> gau.txt;cat gau.txt | sort -u | httpx -silent >> alivegau.txt;
          echo $1 | waybackurls >> waybacks.txt;
          cat waybacks.txt | sort -u | httpx -silent >> alivewaybacks.txt;cat alivegau.txt alivewaybacks.txt | sort -u >> allalive.txt
}

# Alias for Dirsearch

alias dirsearch="python3 /path/to/dirsearch/dirsearch.py -x 301,302,304,400,401,404,500 -e php,sql,html,js,json,asp,aspx,pl,zip,txt,tar,jsp,swf,log,rar"

# Give your js files as input here to get urls and juicy contents 
 # Nothing fancy...useage eg: jsfun <domain>/sesitive.js

jsfun(){
        mkdir -p js;
        cat $1 | while read url; do linkfinder -d -i $url -o cli;done >> js/linkfinder.txt;
        cat $1 | while read url; do secretfinder -i $url -o cli;done >> js/secrets.txt;
}

# OTX
# Edited from https://github.com/Virdoexhunter/OneLinerBashrcCommand

otx()
{
    gron "https://otx.alienvault.com/otxapi/indicator/hostname/url_list/$1?limit=100&page=1" | grep "\burl\b" | gron --ungron | jq | grep http | tr -d '"' | tr -d 'url:';
}
